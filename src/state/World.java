package state;

import view.ColorTheme;
import view.LoggingPanel;

import java.util.ArrayList;
import java.util.Random;

/**
 * Created by Yonne on 05/12/13.
 */
public class World{
    ColorTheme ct;
    Dimensions d;
    Parameters p;
    Random random;
    Controller c;
    private final double max_distance;
    LoggingPanel debug;
    LoggingPanel log;
    Jungle jungle;
    long start_time;
    double running_time;
    long stop_time;
    long pauze_duration;
    boolean train = false;

    public World(Parameters p, Dimensions d, ColorTheme ct, Random random, LoggingPanel log, LoggingPanel debug) {
    	System.out.println("without training");
        this.log = log;
        this.ct = ct;
        this.d = d;
        this.p = p;
        this.random = random;
        this.debug = debug;
        init_world();
        this.c = new Controller(this.p);
        max_distance = StrictMath.sqrt(StrictMath.pow(d.height, 2) + StrictMath.pow(d.width, 2));
    }
    
    public World(Parameters p, Dimensions d, ColorTheme ct, Random random, LoggingPanel log, LoggingPanel debug, boolean train) {
    	System.out.printf("with training\n");
    	this.train = train;
        this.log = log;
        this.ct = ct;
        this.d = d;
        this.p = p;
        this.random = random;
        this.debug = debug;
        init_world();
        this.c = new Controller(this.p);
        if(train)
        {
        	train();
        }
        max_distance = StrictMath.sqrt(StrictMath.pow(d.height, 2) + StrictMath.pow(d.width, 2));
    }

    public int get_width() {
        return this.d.width;
    }

    // train the controller to do what we want it to do.
    public void train()
    {
    	c.train(jungle);
    	
    	// reset the world, but keep the trained controller.
    	//Controller old_c = this.c;
    	//reset(old_c);
    }

    public int get_height() {
        return this.d.height;
    }

    public Dimensions get_dimension() {
        return this.d;
    }

    /**
     * Creates a new group of agents
     *
     * @param agents ArrayList containing Agent-objects
     * @return new Group-object created from the agent-list
     */
    public Group create_group(ArrayList<Agent> agents) {
        return new Group(jungle.pool_size()+1, agents, debug,log, jungle);
    }

    public Jungle get_jungle() {
        return this.jungle;
    }

    public ColorTheme get_color_theme() {
        return this.ct;
    }

    /**
     * Fills the wall_distance array with the relative distances to the walls
     *
     * @param group the group we want to 'sense' the walls for
     * @param a     the current agent we're working with
     * @return ArrayList<Double> filled with relative distances in 4 quadrants
     */
    // @todo Fill method
    public ArrayList<Double> sense_walls(Group group, Agent a) {
        ArrayList<Double> wall_distance = new ArrayList<Double>();
        for (int i = 0; i < p.n_sensors; i++) {

        }
        return wall_distance;
    }

    /**
     * Initializes the world
     * Creates the agents with a random start position
     * Adds the agents in the first group
     * Adds the group to the pool in the jungle
     */
    public void init_world() {
        jungle = new Jungle(ct,debug,log);
        log.known_bugs();
        log.write_parameters(p);
    	ArrayList<Agent> start_list = new ArrayList<Agent>();

    	if(p.trainingDone){
	    	debug.write("Start Positions");
	        for (int i = 0; i < p.nr_of_agents; i++) {
	            final Agent new_agent = init_agent();
	            start_list.add(new_agent);
	            debug.write((i + 1) + "/" + p.nr_of_agents + " : " + "(" + new_agent.get_pos().round(1000).get_x() + "," + new_agent.get_pos().round(1000).get_y() + ")");
	        }
	        Group start_group = create_group(start_list);
	        jungle.add_group(start_group);
    	}
    }


    /**
     * Let each agent move to a new position, generated by the neural controller
     */
    public void step() {
        running_time = time();
        log.update_runningtime(running_time);
        jungle.step(d);
    }

    public Agent init_agent() {
        final double x = random.nextDouble() * d.width;
        final double y = random.nextDouble() * d.height;
        Coordinate start_pos = new Coordinate(x, y);
        final Agent agent = new Agent(start_pos, p, jungle.pool_size()+1, c, log, debug);
        agent.addController(c);
        return agent;
    }

    /**
     * Resets the world
     * Creates a new jungle, clears the logs
     * and sets up the new environment
     */
    public void reset() {
        log.clear();
        debug.clear();
        init_world();
        p.start = false;
        p.first_run = true;
        this.c = new Controller(this.p);
    }
    
    /**
     * Reset the world, use the specified controller
     * @param 	controller
     */
    public void reset(Controller c)
    {
    	log.clear();
    	debug.clear();
    	init_world();
    	p.start=false;
    	p.first_run=true;
    	this.c = c;
    }

    public double time() {
        if (!p.start) {
            return running_time;
        }
        return System.currentTimeMillis() - start_time - pauze_duration;
    }

    public void stop_time() {
        stop_time = System.currentTimeMillis();
    }

    public void start_time() {
        if (p.first_run) {
            start_time = System.currentTimeMillis();
            running_time = 0;
            p.first_run = false;
            pauze_duration = 0;
            return;
        }
        pauze_duration += System.currentTimeMillis() - stop_time;

    }

    public double get_running_time() {
        return running_time;
    }

    /**
     * Forwarder for the human_input, used by the Human class
     * Sets the specific input to 1.0, reverting the rest to 0.0
     * @param index input to be change.
     * 10: left
     * 11: right
     * 12: down
     * 13: up
     * 14: split
     * 15: merge
     */
    public void set_human_input(int index, int group)
    {
        jungle.set_human_input(index, group);
    }

}
